{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╭─────────────────────────────────────────────╮\n",
      "│                  PARAMÈTRES                 │\n",
      "├─────────────────────────────────────────────┤\n",
      "│ LIM_FLUX_CLUSTER      : 3.00e-15 erg/cm²/s \n",
      "│ LIM_FLUX_AGN          : 3.00e-15 erg/cm²/s \n",
      "│ SEARCH_RADIUS_CLUSTER : 30.00    arcsec    \n",
      "│ SEARCH_RADIUS_AGN     : 10.00    arcsec    \n",
      "│ EXT_LIKE_C1           : 33       \n",
      "│ EXT_LIKE_C2           : 15       \n",
      "│ EXT_C1_C2             : 5        \n",
      "│ EXT_LIKE_C1_new       : 80       \n",
      "│ EXT_LIKE_C2_new       : 35       \n",
      "│ EXT_C1_C2_new         : 13       \n",
      "│ window_size           : 3.0      arcmin    \n",
      "│ PNT_DET_ML_SPURIOUS   : 20       \n",
      "│ EXT_LIKE_SPURIOUS     : 15       \n",
      "╰─────────────────────────────────────────────╯\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Backend non-interactif\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from astropy.wcs import WCS\n",
    "from textwrap import fill\n",
    "from astropy.table import Table, vstack, Column\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import search_around_sky\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy.table import join, hstack\n",
    "\n",
    "from constantes import LIM_FLUX_CLUSTER, LIM_FLUX_AGN, SEARCH_RADIUS_CLUSTER, SEARCH_RADIUS_AGN, EXT_LIKE_C1, EXT_LIKE_C2, EXT_C1_C2, PNT_DET_ML_SPURIOUS, EXT_LIKE_SPURIOUS\n",
    "from constantes import print_parameters\n",
    "\n",
    "print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Suppression des doublons Xamin sur les zones de recouvrement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sources Xamin avant la suppresion des doublons: 21152\n",
      "Nombre de sources Xamin apres la suppresion des doublons: 17752\n",
      "Catalogue Xamin sauvegardé dans : ~/Documents/TransformerProject/data/catalogs/Data_10ks/onlyMOSPN/merged_catalog_cleaned.fits\n"
     ]
    }
   ],
   "source": [
    "suppression_doublons_Xamin = True\n",
    "\n",
    "if(suppression_doublons_Xamin):\n",
    "\n",
    "    catalog_path_aftXamin = os.path.expanduser('~/Documents/TransformerProject/data/catalogs/Data_10ks/onlyMOSPN/merged_catalog.fits')\n",
    "    data_Xamin = Table.read(catalog_path_aftXamin)\n",
    "    data_Xamin['new_ID'] = np.arange(len(data_Xamin))\n",
    "\n",
    "    RADIUS_XAMIN = 5  #arcsec\n",
    "\n",
    "    coords = SkyCoord(ra=data_Xamin['PNT_RA'], dec=data_Xamin['PNT_DEC'], unit='deg')\n",
    "\n",
    "    #Calcul de ttes les paires a moins de RADIUS_XAMIN\n",
    "    idx1, idx2, sep2d, _ = coords.search_around_sky(coords, seplimit= RADIUS_XAMIN* u.arcsec)\n",
    "\n",
    "    #Filtrage des paires distinctes\n",
    "    mask = idx1 < idx2\n",
    "    idx1 = idx1[mask]\n",
    "    idx2 = idx2[mask]\n",
    "\n",
    "    to_remove = set()\n",
    "    for i, j in zip(idx1, idx2):\n",
    "        id_i = data_Xamin['new_ID'][i]\n",
    "        id_j = data_Xamin['new_ID'][j]\n",
    "        to_remove.add(i if id_i > id_j else j)\n",
    "\n",
    "    #Suppression des lignes\n",
    "    mask_keep = np.ones(len(data_Xamin), dtype = bool)\n",
    "    mask_keep[list(to_remove)] = False\n",
    "    data_Xamin_cleaned = data_Xamin[mask_keep]\n",
    "\n",
    "    data_Xamin_cleaned.remove_column('new_ID')\n",
    "\n",
    "    # Vu qu'on a supprime des sources la numerotation de ID_Xamin n'etait plus continue\n",
    "    data_Xamin_cleaned.remove_column('ID_Xamin')\n",
    "    data_Xamin_cleaned['ID_Xamin'] = np.arange(len(data_Xamin_cleaned))\n",
    "\n",
    "    print(f\"Nombre de sources Xamin avant la suppresion des doublons: {len(data_Xamin)}\")\n",
    "    print(f\"Nombre de sources Xamin apres la suppresion des doublons: {len(data_Xamin_cleaned)}\")\n",
    "\n",
    "    input_dir = \"~/Documents/TransformerProject/data/catalogs/Data_10ks/onlyMOSPN/\"\n",
    "    output_path = os.path.join(input_dir, \"merged_catalog_cleaned.fits\") \n",
    "    data_Xamin_cleaned.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "    print(f\"Catalogue Xamin sauvegardé dans : {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Noms des chemins vers les catalogues**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "activate_cut_Xamin_with_min_40photons = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes actuelles:\n",
      "['3', '513636967', '148.852551198248', '3.66324683120872', '3747.87232503616', '3475.58376807197', '7621999900000', '0.56', '4.07E+41', '3.21E-17', '2.40E-17', '11.52', '0.8423']\n",
      "\n",
      "Colonnes après renommage:\n",
      "['3', 'ID', 'R.A.', 'Dec', 'px', 'yx', 'm200', 'Tsl', 'Lx_soft', 'flux', 'flux_ABS', 'r500', 'z']\n"
     ]
    }
   ],
   "source": [
    "catalog_path_AMAS  = os.path.expanduser('~/Documents/TransformerProject/data/catalogs/XFSII_25_sx_p18_b05rc02_output.csv')\n",
    "catalog_path_Xamin = os.path.expanduser('~/Documents/TransformerProject/data/catalogs/Data_10ks/onlyMOSPN/merged_catalog_cleaned.fits')\n",
    "catalog_path_AGN   = os.path.expanduser('~/Documents/TransformerProject/data/Flagship_data/FS2_MAMBO_AGN.fits')\n",
    "\n",
    "data_Xamin      = Table.read(catalog_path_Xamin)\n",
    "data_input_AMAS = Table.read(catalog_path_AMAS)\n",
    "data_input_AGN  = Table.read(catalog_path_AGN)\n",
    "\n",
    "data_Xamin['new_ID'] = np.arange(len(data_Xamin))\n",
    "\n",
    "if(activate_cut_Xamin_with_min_40photons):\n",
    "    data_Xamin['Ntot'] = data_Xamin['INST0_EXP'] * data_Xamin['PNT_RATE_MOS'] + data_Xamin['INST1_EXP'] * data_Xamin['PNT_RATE_PN']\n",
    "    mask_Xamin_sup_40ph = (data_Xamin['Ntot'] > 40)\n",
    "    data_Xamin = data_Xamin[mask_Xamin_sup_40ph]\n",
    "\n",
    "new_column_names = ['ID', 'R.A.', 'Dec', 'px', 'yx', 'm200', 'Tsl', 'Lx_soft', 'flux', 'flux_ABS', 'r500', 'z']\n",
    "\n",
    "current_cols = data_input_AMAS.colnames\n",
    "print(\"Colonnes actuelles:\")\n",
    "print(current_cols)\n",
    "\n",
    "for i in range(1, 13): # Renommer uniquement les colonnes 2 à 13\n",
    "    data_input_AMAS.rename_column(current_cols[i], new_column_names[i-1])\n",
    "\n",
    "print(\"\\nColonnes après renommage:\")\n",
    "print(data_input_AMAS.colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Row index=0</i>\n",
       "<table id=\"table131794224760976\">\n",
       "<thead><tr><th>3</th><th>ID</th><th>R.A.</th><th>Dec</th><th>px</th><th>yx</th><th>m200</th><th>Tsl</th><th>Lx_soft</th><th>flux</th><th>flux_ABS</th><th>r500</th><th>z</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>2</td><td>543737908</td><td>151.22570493977</td><td>6.13184952042855</td><td>7150.37004691358</td><td>7040.54097352349</td><td>19800000600000</td><td>0.98</td><td>1.53e+42</td><td>9.79e-17</td><td>7.71e-17</td><td>13.2</td><td>1.0714</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Row index=0>\n",
       "  3       ID          R.A.            Dec               px               yx             m200        Tsl   Lx_soft    flux   flux_ABS   r500     z   \n",
       "int64   int64       float64         float64          float64          float64          int64      float64 float64  float64  float64  float64 float64\n",
       "----- --------- --------------- ---------------- ---------------- ---------------- -------------- ------- -------- -------- -------- ------- -------\n",
       "    2 543737908 151.22570493977 6.13184952042855 7150.37004691358 7040.54097352349 19800000600000    0.98 1.53e+42 9.79e-17 7.71e-17    13.2  1.0714"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input_AMAS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Row index=0</i>\n",
       "<table id=\"table131794224536256\">\n",
       "<thead><tr><th>id</th><th>ra</th><th>dec</th><th>z</th><th>m</th><th>passive</th><th>agn_type</th><th>Lx_h</th><th>Lx_s</th><th>Fx_s_abs</th><th>Fx_s_G14</th><th>NH</th><th>Mbh</th></tr></thead>\n",
       "<thead><tr><th>int64</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>int32</th><th>int32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th><th>float32</th></tr></thead>\n",
       "<tr><td>35353500011970000</td><td>150.84576</td><td>1.9766083</td><td>0.003286787</td><td>7.7614284</td><td>0</td><td>2</td><td>39.93776</td><td>39.478336</td><td>4.417671e-15</td><td>1.2650335e-13</td><td>22.95448</td><td>0.0150628565</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Row index=0>\n",
       "        id            ra       dec         z          m     passive agn_type   Lx_h      Lx_s     Fx_s_abs      Fx_s_G14      NH        Mbh     \n",
       "      int64        float32   float32    float32    float32   int32   int32   float32   float32    float32       float32    float32    float32   \n",
       "----------------- --------- --------- ----------- --------- ------- -------- -------- --------- ------------ ------------- -------- ------------\n",
       "35353500011970000 150.84576 1.9766083 0.003286787 7.7614284       0        2 39.93776 39.478336 4.417671e-15 1.2650335e-13 22.95448 0.0150628565"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input_AGN[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Suppresion des fausses sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "suppr_spurious = False\n",
    "\n",
    "if (suppr_spurious):\n",
    "    mask_spurious = np.logical_or(data_Xamin['PNT_DET_ML'] >= PNT_DET_ML_SPURIOUS, data_Xamin['EXT_LIKE'] >= EXT_LIKE_SPURIOUS)\n",
    "    print(f\"Nombre de sources apres Xamin: {len(data_Xamin)}\")\n",
    "\n",
    "    data_Xamin = data_Xamin[mask_spurious]\n",
    "    print(f\"Nombre de sources apres Xamin sans les fausses sources: {len(data_Xamin)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Filtrage du flux pour les amas et les AGN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "STATISTIQUES DE FILTRAGE\n",
      "Nombre initial d'amas : 18995\n",
      "Nombre d'amas après masque (flux_ABS > 3e-15) : 942\n",
      "\n",
      "==================================================\n",
      "STATISTIQUES DE FILTRAGE\n",
      "Nombre initial d'AGN : 976895\n",
      "Nombre d'AGN après masque (flux_ABS > 3e-15) : 15012\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*50}\")\n",
    "print(\"STATISTIQUES DE FILTRAGE\")\n",
    "print(f\"Nombre initial d'amas : {len(data_input_AMAS)}\")\n",
    "print(f\"Nombre d'amas après masque (flux_ABS > {LIM_FLUX_CLUSTER}) : {len(data_input_AMAS[data_input_AMAS['flux_ABS'] > LIM_FLUX_CLUSTER])}\")\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"STATISTIQUES DE FILTRAGE\")\n",
    "print(f\"Nombre initial d'AGN : {len(data_input_AGN)}\")\n",
    "print(f\"Nombre d'AGN après masque (flux_ABS > {LIM_FLUX_AGN}) : {len(data_input_AGN[data_input_AGN['Fx_s_G14'] > LIM_FLUX_AGN])}\")\n",
    "\n",
    "\n",
    "mask_flux_cluster = data_input_AMAS['flux_ABS'] > LIM_FLUX_CLUSTER\n",
    "data_input_AMAS = data_input_AMAS[mask_flux_cluster]\n",
    "\n",
    "mask_flux_agn = data_input_AGN['Fx_s_G14'] > LIM_FLUX_AGN\n",
    "data_input_AGN = data_input_AGN[mask_flux_agn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Correlator(tableXAMIN, tableINPUT,\n",
    "                           ra_xamin, dec_xamin,\n",
    "                           ra_input, dec_input,\n",
    "                           id_xamin, id_input,\n",
    "                           search_radius):\n",
    "\n",
    "    # ///////////////////// Corrélation /////////////////////////\n",
    "\n",
    "    # Initialisation des tables de résultats\n",
    "    unique_matches    = Table(names=(id_input, id_xamin, 'DISTANCE'), dtype=('i8', 'i8', 'f4'))\n",
    "    ambiguous_matches = Table(names=(id_input,  'EXT_RATE_MOS', 'EXT_RATE_PN', id_xamin, 'DISTANCE'), dtype=('i8', 'f8', 'f8', 'i8', 'f4'))\n",
    "\n",
    "    # Conversion en SkyCoord\n",
    "    coords_bef = SkyCoord(ra=tableINPUT[ra_input]*u.deg, dec=tableINPUT[dec_input]*u.deg)\n",
    "    coords_aft = SkyCoord(ra=tableXAMIN[ra_xamin]*u.deg, dec=tableXAMIN[dec_xamin]*u.deg)\n",
    "\n",
    "    # Rayon de recherche\n",
    "    search_radius_arcsec = (search_radius* u.deg).to(u.arcsec)  # en arcsec\n",
    "\n",
    "    for i in range(len(tableXAMIN)):\n",
    "\n",
    "        dist_arcsec = coords_aft[i].separation(coords_bef).arcsecond\n",
    "        matches = np.where(dist_arcsec < search_radius_arcsec.value)[0]\n",
    "        n_matches = len(matches)\n",
    "        \n",
    "        if n_matches == 1:\n",
    "            unique_matches.add_row({\n",
    "                id_xamin: tableXAMIN[id_xamin][i],\n",
    "                id_input: tableINPUT[id_input][matches[0]],\n",
    "                'DISTANCE': dist_arcsec[matches[0]]\n",
    "            })\n",
    "        elif n_matches > 1:\n",
    "            for j in matches:\n",
    "                ambiguous_matches.add_row({\n",
    "                    id_xamin: tableXAMIN[id_xamin][i],\n",
    "                    id_input: tableINPUT[id_input][j],\n",
    "                    'EXT_RATE_MOS': tableXAMIN['EXT_RATE_MOS'][i],\n",
    "                    'EXT_RATE_PN': tableXAMIN['EXT_RATE_PN'][i],\n",
    "                    'DISTANCE': dist_arcsec[j]\n",
    "                })\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"- Correspondances uniques: \\033[91m{len(unique_matches)}\\033[0m\")\n",
    "    print(f\"- Nombre de sources du catalogues Xamin correlées avec ambiguités: \\033[91m{len(set(ambiguous_matches[id_xamin]))}\\033[0m \\ncad le nombre de sources Xamin qui ont des correspondances multiples avec celles  du catalogue d'entree\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # /////// Création de la table des matches avec distance minimale ///////////\n",
    "\n",
    "    ambiguous_matches_min_dist = Table(names=ambiguous_matches.colnames, dtype=ambiguous_matches.dtype)\n",
    "\n",
    "    for id in set(ambiguous_matches[id_xamin]): # Groupement par ID et recherche de la distance minimale\n",
    "        \n",
    "        matches_for_id = ambiguous_matches[ambiguous_matches[id_xamin] == id] # Sélection des matches pour cet ID\n",
    "        idx_min = np.argmin(matches_for_id['DISTANCE']) # Trouver l'indice du match avec la distance minimale\n",
    "        ambiguous_matches_min_dist.add_row(matches_for_id[idx_min]) # Ajouter ce match à la nouvelle table\n",
    "\n",
    "    # Vérification\n",
    "    n_ambiguous = len(set(ambiguous_matches[id_xamin]))\n",
    "    n_selected = len(ambiguous_matches_min_dist)\n",
    "    check_passed = n_ambiguous == n_selected\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Litiges : SÉLECTION PAR DISTANCE MINIMALE\")\n",
    "    print(f\"Nombre d'IDs ambigus uniques : {n_ambiguous}\")\n",
    "    print(f\"Correspondances sélectionnées : {n_selected}\")\n",
    "    print(f\"Vérification : {'✓ OK' if check_passed else '✗ ÉCHEC'} ({n_ambiguous} == {n_selected})\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    \n",
    "    # ///////////////////// Concaténation /////////////////////////\n",
    "\n",
    "    common_columns = [id_input, id_xamin, 'DISTANCE'] # Sélection des colonnes communes\n",
    "    unique_subset = unique_matches[common_columns]\n",
    "    ambiguous_subset = ambiguous_matches_min_dist[common_columns]\n",
    "    final_catalog = vstack([unique_subset, ambiguous_subset])\n",
    "    final_catalog.sort(id_input)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"                     *** BILAN ***\")\n",
    "    print(f\"Nombre de sources du catalogue d'entree: {len(tableINPUT)}\")\n",
    "    print(f\"Nombre de correspondances uniques : {len(unique_matches)}\")\n",
    "    print(f\"Nombre de correspondances ambigües traitées : {len(ambiguous_matches_min_dist)}\")\n",
    "    print(f\"\\033[91mTotal dans le catalogue final : {len(final_catalog)}\\033[0m\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    matched_full = join(final_catalog, tableXAMIN, keys=id_xamin, join_type='inner')\n",
    "    matched_full = join(matched_full, tableINPUT, keys=id_input, join_type='inner')\n",
    "    print(f\"\\nDimensions de la table finale: {len(matched_full)} lignes x {len(matched_full.columns)} colonnes\")\n",
    "\n",
    "    return matched_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "- Correspondances uniques: \u001b[91m496\u001b[0m\n",
      "- Nombre de sources du catalogues Xamin correlées avec ambiguités: \u001b[91m2\u001b[0m \n",
      "cad le nombre de sources Xamin qui ont des correspondances multiples avec celles  du catalogue d'entree\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Litiges : SÉLECTION PAR DISTANCE MINIMALE\n",
      "Nombre d'IDs ambigus uniques : 2\n",
      "Correspondances sélectionnées : 2\n",
      "Vérification : ✓ OK (2 == 2)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "                     *** BILAN ***\n",
      "Nombre de sources du catalogue d'entree: 942\n",
      "Nombre de correspondances uniques : 496\n",
      "Nombre de correspondances ambigües traitées : 2\n",
      "\u001b[91mTotal dans le catalogue final : 498\u001b[0m\n",
      "============================================================\n",
      "\n",
      "Dimensions de la table finale: 498 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "data_correl_AMAS = Correlator(data_Xamin, data_input_AMAS,\n",
    "                            ra_xamin = 'EXT_RA', dec_xamin = 'EXT_DEC',\n",
    "                            ra_input = 'R.A.', dec_input = 'Dec',\n",
    "                            id_xamin = 'ID_Xamin', id_input = 'ID',\n",
    "                            search_radius = SEARCH_RADIUS_CLUSTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "- Correspondances uniques: \u001b[91m7076\u001b[0m\n",
      "- Nombre de sources du catalogues Xamin correlées avec ambiguités: \u001b[91m82\u001b[0m \n",
      "cad le nombre de sources Xamin qui ont des correspondances multiples avec celles  du catalogue d'entree\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Litiges : SÉLECTION PAR DISTANCE MINIMALE\n",
      "Nombre d'IDs ambigus uniques : 82\n",
      "Correspondances sélectionnées : 82\n",
      "Vérification : ✓ OK (82 == 82)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "                     *** BILAN ***\n",
      "Nombre de sources du catalogue d'entree: 15012\n",
      "Nombre de correspondances uniques : 7076\n",
      "Nombre de correspondances ambigües traitées : 82\n",
      "\u001b[91mTotal dans le catalogue final : 7158\u001b[0m\n",
      "============================================================\n",
      "\n",
      "Dimensions de la table finale: 7158 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "data_correl_AGN = Correlator(data_Xamin, data_input_AGN,\n",
    "                                ra_xamin = 'PNT_RA', dec_xamin = 'PNT_DEC',\n",
    "                                ra_input = 'ra', dec_input = 'dec',\n",
    "                                id_xamin = 'ID_Xamin', id_input = 'id',\n",
    "                                search_radius = SEARCH_RADIUS_AGN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sauvegarde des fichiers de corrélations filtrés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue complet sauvegardé dans : /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Clusters_matches_r30arcsec_flux3e-15_10ks.fits\n",
      "Dimensions : 498 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.expanduser(f'~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Clusters_matches_r{SEARCH_RADIUS_CLUSTER*3600:.2g}arcsec_flux{LIM_FLUX_CLUSTER}_10ks.fits')\n",
    "data_correl_AMAS.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "with fits.open(output_path, mode='update') as hdul:\n",
    "    hdr = hdul[1].header\n",
    "    hdr['COMMENT'] = 'Catalogue complet des correspondances avant/apres Xamin'\n",
    "    hdr['R_MATCH'] = (SEARCH_RADIUS_CLUSTER, 'Rayon de matching (arcsec)')\n",
    "    hdr['N_MATCH'] = (len(data_correl_AMAS), 'Nombre de correspondances')\n",
    "\n",
    "print(f\"Catalogue complet sauvegardé dans : {output_path}\")\n",
    "print(f\"Dimensions : {len(data_correl_AMAS)} lignes x {len(data_correl_AMAS.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue complet sauvegardé dans : /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/AGN_matches_r10arcsec_flux3e-15_10ks.fits\n",
      "Dimensions : 7158 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.expanduser(f'~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/AGN_matches_r{SEARCH_RADIUS_AGN*3600:.2g}arcsec_flux{LIM_FLUX_AGN}_10ks.fits')\n",
    "data_correl_AGN.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "with fits.open(output_path, mode='update') as hdul:\n",
    "    hdr = hdul[1].header\n",
    "    hdr['COMMENT'] = 'Catalogue complet des correspondances avant/apres Xamin'\n",
    "    hdr['R_MATCH'] = (SEARCH_RADIUS_AGN, 'Rayon de matching (arcsec)')\n",
    "    hdr['N_MATCH'] = (len(data_correl_AGN), 'Nombre de correspondances')\n",
    "\n",
    "print(f\"Catalogue complet sauvegardé dans : {output_path}\")\n",
    "print(f\"Dimensions : {len(data_correl_AGN)} lignes x {len(data_correl_AGN.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Suppression des multi-correspondances**\n",
    "\n",
    "Rappel: correlation Output Xamin vs Input Clusters/AGN\n",
    "\n",
    "donc plusieurs sources Xamin peuvent avoir ete correlee avec une meme source d entree! d ou la redondance des identifiants des donnees d entree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_repet_in_data(table, key):\n",
    "    ids = table[key].data\n",
    "    unique_ids, counts = np.unique(ids, return_counts = True)\n",
    "    stats = {\n",
    "        'tot_entrees' : len(table),\n",
    "        'ids_uniques' : len(unique_ids),\n",
    "        'ids_dupliques' : np.sum(counts>1),\n",
    "        'max_repetitions' : np.max(counts),\n",
    "        'nbre_redondants' : np.sum(counts - 1)\n",
    "    }\n",
    "    print(\"-\"*30)\n",
    "    print(f'Total entrees dans la table: {stats['tot_entrees']}')\n",
    "    print(f'Nbre d\\'{key} distincts: {stats['ids_uniques']}')\n",
    "    print(f'Nbre d\\'{key} dupliques: {stats['ids_dupliques']}')\n",
    "    print(f'Nbre max de rep: {stats['max_repetitions']}')\n",
    "    print(f'Nbre de val redondantes (le nbre a suppr si plus de redondance): {stats['nbre_redondants']}')\n",
    "\n",
    "    mask = ~np.isin(ids, unique_ids)\n",
    "    #print(mask.shape)\n",
    "    #print(ids.shape)\n",
    "    duplicate_ids = unique_ids[counts > 1]\n",
    "    mask = np.isin(ids, duplicate_ids)\n",
    "    return ids[mask]\n",
    "\n",
    "def suppr_redondance(table, key):\n",
    "    table_grouped = table.group_by(key)\n",
    "\n",
    "    min_indices = []\n",
    "    for i in range(len(table_grouped.groups)):\n",
    "        grp = table_grouped.groups[i]\n",
    "        min_idx = np.argmin(grp['DISTANCE'])\n",
    "        min_indices.append(table_grouped.groups.indices[i] + min_idx)\n",
    "    table_min_per_id = table[min_indices]\n",
    "    return table_min_per_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Total entrees dans la table: 7158\n",
      "Nbre d'id distincts: 7154\n",
      "Nbre d'id dupliques: 4\n",
      "Nbre max de rep: 2\n",
      "Nbre de val redondantes (le nbre a suppr si plus de redondance): 4\n",
      "------------------------------\n",
      "Total entrees dans la table: 498\n",
      "Nbre d'ID distincts: 481\n",
      "Nbre d'ID dupliques: 17\n",
      "Nbre max de rep: 2\n",
      "Nbre de val redondantes (le nbre a suppr si plus de redondance): 17\n",
      "------------------------------\n",
      "\n",
      "AGN: 7158\n",
      "AGN restants: 7154\n",
      "\n",
      "Amas: 498\n",
      "Amas restants: 481\n"
     ]
    }
   ],
   "source": [
    "id_redondants_AGN  = stat_repet_in_data(data_correl_AGN, key='id')\n",
    "ID_redondants_AMAS = stat_repet_in_data(data_correl_AMAS, key='ID')\n",
    "\n",
    "data_correl_AMAS_filt = suppr_redondance(data_correl_AMAS, key ='ID')\n",
    "data_correl_AGN_filt  = suppr_redondance(data_correl_AGN, key ='id')\n",
    "\n",
    "print(\"-\"*30)\n",
    "print(f\"\\nAGN: {len(data_correl_AGN)}\")\n",
    "print(f\"AGN restants: {len(data_correl_AGN_filt)}\")\n",
    "print(f\"\\nAmas: {len(data_correl_AMAS)}\")\n",
    "print(f\"Amas restants: {len(data_correl_AMAS_filt)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sauvegarde des fichiers de correlations filtres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue complet sauvegardé dans : /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Clusters_matches_r30arcsec_flux3e-15_10ks_filtered.fits\n",
      "Dimensions : 481 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.expanduser(f'~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Clusters_matches_r{SEARCH_RADIUS_CLUSTER*3600:.2g}arcsec_flux{LIM_FLUX_CLUSTER}_10ks_filtered.fits')\n",
    "data_correl_AMAS_filt.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "with fits.open(output_path, mode='update') as hdul:\n",
    "    hdr = hdul[1].header\n",
    "    hdr['COMMENT'] = 'Catalogue complet des correspondances avant/apres Xamin'\n",
    "    hdr['R_MATCH'] = (SEARCH_RADIUS_CLUSTER, 'Rayon de matching (arcsec)')\n",
    "    hdr['N_MATCH'] = (len(data_correl_AMAS_filt), 'Nombre de correspondances')\n",
    "\n",
    "print(f\"Catalogue complet sauvegardé dans : {output_path}\")\n",
    "print(f\"Dimensions : {len(data_correl_AMAS_filt)} lignes x {len(data_correl_AMAS_filt.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalogue complet sauvegardé dans : /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/AGN_matches_r10arcsec_flux3e-15_10ks_filtered.fits\n",
      "Dimensions : 7154 lignes x 128 colonnes\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.expanduser(f'~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/AGN_matches_r{SEARCH_RADIUS_AGN*3600:.2g}arcsec_flux{LIM_FLUX_AGN}_10ks_filtered.fits')\n",
    "data_correl_AGN_filt.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "with fits.open(output_path, mode='update') as hdul:\n",
    "    hdr = hdul[1].header\n",
    "    hdr['COMMENT'] = 'Catalogue complet des correspondances avant/apres Xamin'\n",
    "    hdr['R_MATCH'] = (SEARCH_RADIUS_AGN, 'Rayon de matching (arcsec)')\n",
    "    hdr['N_MATCH'] = (len(data_correl_AGN_filt), 'Nombre de correspondances')\n",
    "\n",
    "print(f\"Catalogue complet sauvegardé dans : {output_path}\")\n",
    "print(f\"Dimensions : {len(data_correl_AGN_filt)} lignes x {len(data_correl_AGN_filt.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Nombre de C1 et C2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompteurC1C2(data, name, ext_c1_c2 = EXT_C1_C2, ext_like_c1 = EXT_LIKE_C1, ext_like_c2 = EXT_LIKE_C2):\n",
    "    data_numeric = data.to_pandas()\n",
    "\n",
    "    # Définition des classes C1 et C2\n",
    "    cond_C1 = np.logical_and((data_numeric['EXT'] > ext_c1_c2) , (data_numeric['EXT_LIKE'] >= ext_like_c1))\n",
    "    cond_C2 = np.logical_and(np.logical_and((data_numeric['EXT'] > ext_c1_c2) , (data_numeric['EXT_LIKE'] < ext_like_c1)),\n",
    "                            (data_numeric['EXT_LIKE'] > ext_like_c2))\n",
    "\n",
    "    n_C1 = sum(cond_C1)\n",
    "    n_C2 = sum(cond_C2)\n",
    "    ni_C1_ni_C2 = len(data_numeric) - (n_C1+n_C2)\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*70)\n",
    "    print(f\"Total dans le catalogue {name} : {len(data_numeric)}\")\n",
    "    print(f\"\\nNombre d'amas dans la classe C1 (EXT>{ext_c1_c2} ET EXT_LIKE>={ext_like_c1}): {n_C1}\")\n",
    "    print(f\"Nombre d'amas dans la classe C2 (EXT>{ext_c1_c2} ET {ext_like_c2}<EXT_LIKE<{ext_like_c1}): {n_C2}\")\n",
    "    print(f\"Nombre d'amas ni dans C1, ni dans C2: {ni_C1_ni_C2}\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================================================================\n",
      "Total dans le catalogue Xamin : 17752\n",
      "\n",
      "Nombre d'amas dans la classe C1 (EXT>5 ET EXT_LIKE>=33): 117\n",
      "Nombre d'amas dans la classe C2 (EXT>5 ET 15<EXT_LIKE<33): 178\n",
      "Nombre d'amas ni dans C1, ni dans C2: 17457\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Total dans le catalogue AMAS : 481\n",
      "\n",
      "Nombre d'amas dans la classe C1 (EXT>5 ET EXT_LIKE>=33): 93\n",
      "Nombre d'amas dans la classe C2 (EXT>5 ET 15<EXT_LIKE<33): 67\n",
      "Nombre d'amas ni dans C1, ni dans C2: 321\n",
      "======================================================================\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Total dans le catalogue AGN : 7154\n",
      "\n",
      "Nombre d'amas dans la classe C1 (EXT>5 ET EXT_LIKE>=33): 33\n",
      "Nombre d'amas dans la classe C2 (EXT>5 ET 15<EXT_LIKE<33): 58\n",
      "Nombre d'amas ni dans C1, ni dans C2: 7063\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "CompteurC1C2(data_Xamin, \"Xamin\")\n",
    "CompteurC1C2(data_correl_AMAS_filt, \"AMAS\")\n",
    "CompteurC1C2(data_correl_AGN_filt, \"AGN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nombre de valeurs communes dans ID_Xamin : 123\n"
     ]
    }
   ],
   "source": [
    "# Convertir les colonnes ID_Xamin en tableaux numpy\n",
    "ids_clusters = np.array(data_correl_AMAS_filt['ID_Xamin'])\n",
    "ids_agn = np.array(data_correl_AGN_filt['ID_Xamin'])\n",
    "\n",
    "# Trouver les intersections\n",
    "common_ids = np.intersect1d(ids_clusters, ids_agn)\n",
    "num_common = len(common_ids)\n",
    "\n",
    "print(f\"\\nNombre de valeurs communes dans ID_Xamin : {num_common}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de masques booléens\n",
    "mask_clusters = np.isin(data_correl_AMAS_filt['ID_Xamin'], common_ids)\n",
    "mask_agn = np.isin(data_correl_AGN_filt['ID_Xamin'], common_ids)\n",
    "mask_Xamin = np.isin(data_Xamin['ID_Xamin'], common_ids)\n",
    "\n",
    "# Filtrage des tables\n",
    "clusters_myst = data_correl_AMAS_filt[mask_clusters]\n",
    "agn_myst = data_correl_AGN_filt[mask_agn]\n",
    "Xamin_myst = data_Xamin[mask_Xamin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reconnaissance des fausses sources**: sources non correlees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Nombre de fausses non correlees: 10240\n"
     ]
    }
   ],
   "source": [
    "mask_NC = ~np.isin(data_Xamin['ID_Xamin'], np.union1d(data_correl_AMAS_filt['ID_Xamin'], data_correl_AGN_filt['ID_Xamin']))\n",
    "data_NC = data_Xamin[mask_NC]\n",
    "print(f\"=> Nombre de fausses non correlees: {len(data_NC)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Sauvegarde du fichier des fausses sources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Catalogue complet sauvegardé dans : /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious_10ks.fits\n",
      "Dimensions : 10240 lignes x 114 colonnes\n"
     ]
    }
   ],
   "source": [
    "output_filename = f\"Spurious_10ks.fits\"\n",
    "output_path = os.path.expanduser(f'~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/{output_filename}')\n",
    "data_NC.write(output_path, format='fits', overwrite=True)\n",
    "\n",
    "with fits.open(output_path, mode='update') as hdul:\n",
    "    hdr = hdul[1].header\n",
    "    hdr['COMMENT'] = 'Spurious sources (not correlated Xamin sources with the input catlog of AGNs and clusters)'\n",
    "\n",
    "print(f\"\\nCatalogue complet sauvegardé dans : {output_path}\")\n",
    "print(f\"Dimensions : {len(data_NC)} lignes x {len(data_NC.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bilan global**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AffichageStatistiquesGlobales(data_xamin, data_amas, data_agn, data_nc, suppression_spurious = False):\n",
    "    def suppr_spurious(data):\n",
    "        mask_spurious = np.logical_or(data['PNT_DET_ML'] >= PNT_DET_ML_SPURIOUS, data['EXT_LIKE'] >= EXT_LIKE_SPURIOUS)\n",
    "        data = data[mask_spurious]\n",
    "        return data\n",
    "    \n",
    "    if(suppression_spurious):\n",
    "        data_xamin = suppr_spurious(data_xamin)\n",
    "        data_amas  = suppr_spurious(data_amas)\n",
    "        data_agn   = suppr_spurious(data_agn)\n",
    "        data_nc    = suppr_spurious(data_nc)\n",
    "\n",
    "    # Nombre de sources Xamin a la fois correle a un amas et un AGN\n",
    "    common_ids = np.intersect1d(np.array(data_amas['ID_Xamin']), np.array(data_agn['ID_Xamin']))\n",
    "    num_common = len(common_ids)\n",
    "\n",
    "    print(f\"- Nombre de sources Xamin: {len(data_xamin)}\")\n",
    "    print(f\"- Nombre d'amas: {len(data_amas) - num_common}\")\n",
    "    print(f\"- Nombre d'AGN: {len(data_agn) - num_common}\")\n",
    "    print(f\"- Nombre d'amas + AGN: {num_common}\")\n",
    "    print(f\"- Nombre de fausses non correlees: {len(data_nc)}\")\n",
    "    print(f\"\\n- Nombre d'amas au total: {len(data_amas)}\")\n",
    "    print(f\"- Nombre d'AGN au total: {len(data_agn)}\")\n",
    "    print(f\"\\nVerficication de len(data_nc) + len(data_agn) + len(data_amas) == len(data_Xamin): {len(data_nc) + len(data_agn) + len(data_amas)==len(data_xamin)}\")\n",
    "    print(f\"Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common == len(data_Xamin): {len(data_nc) + len(data_agn) + len(data_amas)- num_common==len(data_xamin)}\")\n",
    "    print(f\"Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common = {len(data_nc) + len(data_agn) + len(data_amas)- num_common}\")\n",
    "\n",
    "    total_sources = len(data_xamin)\n",
    "    print(\"-\"*30)\n",
    "    print(f\"\\n\\033[1m Amas \\033[0m : {((len(data_amas)- num_common) / total_sources) * 100:>5.1f}%\")\n",
    "    print(f\"\\n\\033[1m AGN \\033[0m : {((len(data_agn) - num_common)/ total_sources) * 100:>5.1f}%\")\n",
    "    print(f\"\\n\\033[1m Amas + AGN \\033[0m : {(num_common/ total_sources) * 100:>5.1f}%\")\n",
    "    print(f\"\\n\\033[1m Spurious \\033[0m : {(len(data_nc) / total_sources) * 100:>5.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Nombre de sources Xamin: 17752\n",
      "- Nombre d'amas: 358\n",
      "- Nombre d'AGN: 7031\n",
      "- Nombre d'amas + AGN: 123\n",
      "- Nombre de fausses non correlees: 10240\n",
      "\n",
      "- Nombre d'amas au total: 481\n",
      "- Nombre d'AGN au total: 7154\n",
      "\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas) == len(data_Xamin): False\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common == len(data_Xamin): True\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common = 17752\n",
      "------------------------------\n",
      "\n",
      "\u001b[1m Amas \u001b[0m :   2.0%\n",
      "\n",
      "\u001b[1m AGN \u001b[0m :  39.6%\n",
      "\n",
      "\u001b[1m Amas + AGN \u001b[0m :   0.7%\n",
      "\n",
      "\u001b[1m Spurious \u001b[0m :  57.7%\n"
     ]
    }
   ],
   "source": [
    "AffichageStatistiquesGlobales(data_Xamin, data_correl_AMAS_filt, data_correl_AGN_filt, data_NC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Nombre de sources Xamin: 8988\n",
      "- Nombre d'amas: 185\n",
      "- Nombre d'AGN: 6170\n",
      "- Nombre d'amas + AGN: 111\n",
      "- Nombre de fausses non correlees: 2522\n",
      "\n",
      "- Nombre d'amas au total: 296\n",
      "- Nombre d'AGN au total: 6281\n",
      "\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas) == len(data_Xamin): False\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common == len(data_Xamin): True\n",
      "Verficication de len(data_nc) + len(data_agn) + len(data_amas)- num_common = 8988\n",
      "------------------------------\n",
      "\n",
      "\u001b[1m Amas \u001b[0m :   2.1%\n",
      "\n",
      "\u001b[1m AGN \u001b[0m :  68.6%\n",
      "\n",
      "\u001b[1m Amas + AGN \u001b[0m :   1.2%\n",
      "\n",
      "\u001b[1m Spurious \u001b[0m :  28.1%\n"
     ]
    }
   ],
   "source": [
    "AffichageStatistiquesGlobales(data_Xamin, data_correl_AMAS_filt, data_correl_AGN_filt, data_NC, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bilan pour les sources entre 40 et 60 photons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = f\"~/Documents/TransformerProject/results/Correl_clusters_agn_10ks\"\n",
    "PATHS = {'clusters': os.path.expanduser(f\"{BASE_PATH}/Clusters_matches_r{SEARCH_RADIUS_CLUSTER*3600:.0f}arcsec_flux{LIM_FLUX_CLUSTER}_10ks_filtered.fits\"),\n",
    "         'agn': os.path.expanduser(f\"{BASE_PATH}/AGN_matches_r{SEARCH_RADIUS_AGN*3600:.0f}arcsec_flux{LIM_FLUX_AGN}_10ks_filtered.fits\"),\n",
    "         'NC':os.path.expanduser(f\"{BASE_PATH}/Spurious_10ks.fits\")}\n",
    "\n",
    "# Définition des intervalles\n",
    "RANGES = {'40-50': (40, 50),\n",
    "          '50-60': (50, 60)}\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Charge les données et calcule Ntot\"\"\"\n",
    "    data = Table.read(path)\n",
    "    #data['Ntot'] = data['INST0_EXP'] * data['PNT_RATE_MOS'] + data['INST1_EXP'] * data['PNT_RATE_PN']\n",
    "    data['Ntot'] = data['PNT_SCTS_MOS'] + data['PNT_SCTS_PN']\n",
    "    return data\n",
    "\n",
    "# Filtrage des données\n",
    "def filter_data(data_dict):\n",
    "    result = {}  \n",
    "    for key in data_dict:  # Parcourir chaque type de données (clusters et AGN)\n",
    "        for range_name, (Nmin, Nmax) in RANGES.items(): # Parcourir chaque intervalle (40-50 et 50-60)\n",
    "            mask = (data_dict[key]['Ntot'] >= Nmin) & (data_dict[key]['Ntot'] <= Nmax)\n",
    "            result[f\"{key}_{range_name}\"] = data_dict[key][mask] # Filtrer et stocker dans le dictionnaire\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AffichageStatistiques(chemin, suppression_spurious = False):\n",
    "    data = {key: load_data(path) for key, path in chemin.items()}\n",
    "    filtered_data = filter_data(data)\n",
    "    \n",
    "    def suppr_spurious(data):\n",
    "        mask_spurious = np.logical_or(data['PNT_DET_ML'] >= PNT_DET_ML_SPURIOUS, data['EXT_LIKE'] >= EXT_LIKE_SPURIOUS)\n",
    "        data = data[mask_spurious]\n",
    "        return data\n",
    "    \n",
    "    # Accès aux tables filtrées\n",
    "    clusters_40_50 = filtered_data['clusters_40-50']\n",
    "    clusters_50_60 = filtered_data['clusters_50-60']\n",
    "    agn_40_50      = filtered_data['agn_40-50']\n",
    "    agn_50_60      = filtered_data['agn_50-60']\n",
    "    spurious_40_50 = filtered_data['NC_40-50']\n",
    "    spurious_50_60 = filtered_data['NC_50-60']\n",
    "\n",
    "    if(suppression_spurious):\n",
    "        clusters_40_50 = suppr_spurious(clusters_40_50)\n",
    "        clusters_50_60 = suppr_spurious(clusters_50_60)\n",
    "        agn_40_50      = suppr_spurious(agn_40_50)\n",
    "        agn_50_60      = suppr_spurious(agn_50_60)\n",
    "        spurious_40_50 = suppr_spurious(spurious_40_50)  \n",
    "        spurious_50_60 = suppr_spurious(spurious_50_60)\n",
    "    \n",
    "    common_ids_40_50 = np.intersect1d(np.array(clusters_40_50['ID_Xamin']), np.array(agn_40_50['ID_Xamin']))\n",
    "    num_common_40_50 = len(common_ids_40_50)\n",
    "\n",
    "    common_ids_50_60 = np.intersect1d(np.array(clusters_50_60['ID_Xamin']), np.array(agn_50_60['ID_Xamin']))\n",
    "    num_common_50_60 = len(common_ids_50_60)\n",
    "\n",
    "    print(f'Nombre de sources (40-50) : {len(clusters_40_50)+len(agn_40_50)+len(spurious_40_50)-num_common_40_50}')\n",
    "    print(f'Nombre de sources (50-60) : {len(clusters_50_60)+len(agn_50_60)+len(spurious_50_60)-num_common_50_60}')\n",
    "\n",
    "    # Pourcentage\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"{:^60}\".format(\"STATISTIQUES\"))\n",
    "    print(\"=\"*60)\n",
    "    for category in ['clusters', 'agn', 'clusters_agn', 'NC']:\n",
    "        print(f\"\\n\\033[1m{category.upper()}\\033[0m\")\n",
    "        print(\"-\"*30)\n",
    "    \n",
    "        for range_name in RANGES.keys():\n",
    "            key = f\"{category}_{range_name}\"\n",
    "            \n",
    "            if(category != 'clusters_agn'):\n",
    "                if(suppression_spurious):\n",
    "                    n_sources = len(suppr_spurious(filtered_data[key]))\n",
    "                else:\n",
    "                    n_sources = len(filtered_data[key])\n",
    "            if range_name == '40-50':\n",
    "                if category == 'clusters' or category == 'agn':\n",
    "                    n_sources = n_sources - num_common_40_50\n",
    "                if category == 'clusters_agn':\n",
    "                    n_sources = num_common_40_50\n",
    "                total_sources = len(clusters_40_50)+len(agn_40_50)+len(spurious_40_50) - num_common_40_50\n",
    "            else:\n",
    "                if category == 'clusters' or category == 'agn':\n",
    "                    n_sources = n_sources - num_common_50_60\n",
    "                if category == 'clusters_agn':\n",
    "                    n_sources = num_common_50_60\n",
    "                total_sources = len(clusters_50_60)+len(agn_50_60)+len(spurious_50_60) - num_common_50_60\n",
    "            global_percentage = (n_sources / total_sources) * 100\n",
    "            \n",
    "            print(f\"• Intervalle {range_name}: {n_sources:>4} {global_percentage:>5.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sources (40-50) : 949\n",
      "Nombre de sources (50-60) : 674\n",
      "\n",
      "============================================================\n",
      "                        STATISTIQUES                        \n",
      "============================================================\n",
      "\n",
      "\u001b[1mCLUSTERS\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:   20   2.1%\n",
      "• Intervalle 50-60:    9   1.3%\n",
      "\n",
      "\u001b[1mAGN\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:  767  80.8%\n",
      "• Intervalle 50-60:  610  90.5%\n",
      "\n",
      "\u001b[1mCLUSTERS_AGN\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:   14   1.5%\n",
      "• Intervalle 50-60:   10   1.5%\n",
      "\n",
      "\u001b[1mNC\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:  148  15.6%\n",
      "• Intervalle 50-60:   45   6.7%\n"
     ]
    }
   ],
   "source": [
    "AffichageStatistiques(PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sources (40-50) : 949\n",
      "Nombre de sources (50-60) : 674\n",
      "\n",
      "============================================================\n",
      "                        STATISTIQUES                        \n",
      "============================================================\n",
      "\n",
      "\u001b[1mCLUSTERS\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:   20   2.1%\n",
      "• Intervalle 50-60:    9   1.3%\n",
      "\n",
      "\u001b[1mAGN\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:  767  80.8%\n",
      "• Intervalle 50-60:  610  90.5%\n",
      "\n",
      "\u001b[1mCLUSTERS_AGN\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:   14   1.5%\n",
      "• Intervalle 50-60:   10   1.5%\n",
      "\n",
      "\u001b[1mNC\u001b[0m\n",
      "------------------------------\n",
      "• Intervalle 40-50:  148  15.6%\n",
      "• Intervalle 50-60:   45   6.7%\n"
     ]
    }
   ],
   "source": [
    "AffichageStatistiques(PATHS, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Overlays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tile_with_sources_after_correlation(ra, dec, mr,\n",
    "                                            show_Xamin_sources,\n",
    "                                            show_ID_and_flux,\n",
    "                                            imgs_dir = \"/local/home/sh275430/Documents/TransformerProject/data/catalogs/Data_10ks/imgs\", \n",
    "                                            output_dir = \"~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Ambigous_images\"):\n",
    "    \"\"\"\n",
    "    Plot a specific tile image with sources overlaid after correlation analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ra : float\n",
    "        Right Ascension coordinate (e.g., 146.75)\n",
    "    dec : float \n",
    "        Declination coordinate (e.g., -1.75)\n",
    "    mr : bool\n",
    "        True for wavelet-transformed images\n",
    "    show_Xamin_sources : bool\n",
    "        True for showing Xamin sources\n",
    "    imgs_dir : str\n",
    "        Directory containing the mosaic FITS files\n",
    "    output_dir : str\n",
    "        Directory to save the output plots\n",
    "    \"\"\"\n",
    "    # Resolve paths\n",
    "    imgs_dir = os.path.expanduser(imgs_dir)\n",
    "    output_dir = os.path.expanduser(output_dir + f'{'/Wavelets_images' if mr else '/Photons_images'}')\n",
    "    \n",
    "    # Construct image filename based on mr parameter\n",
    "    img_file = f\"Tile-{ra}-{dec}_m12pn_b2_mosaic{'_mr' if mr else ''}.fits\"\n",
    "    img_path = os.path.join(imgs_dir, img_file)\n",
    "    \n",
    "    # Load image data\n",
    "    with fits.open(img_path) as hdul:\n",
    "        img_data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "        wcs = WCS(header)\n",
    "    \n",
    "    # Convert coordinates to pixels\n",
    "    coords_AGN = SkyCoord(agn_myst[\"ra\"], \n",
    "                          agn_myst[\"dec\"], \n",
    "                          frame='icrs', \n",
    "                          unit='deg')\n",
    "    x_AGN, y_AGN = wcs.world_to_pixel(coords_AGN)\n",
    "\n",
    "    coords_AMAS = SkyCoord(clusters_myst[\"R.A.\"],\n",
    "                          clusters_myst[\"Dec\"], \n",
    "                          frame='icrs', \n",
    "                          unit='deg')\n",
    "    x_AMAS, y_AMAS = wcs.world_to_pixel(coords_AMAS)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': wcs})\n",
    "    \n",
    "    # Display image with proper scaling\n",
    "    ax.imshow(\n",
    "        img_data,\n",
    "        alpha=1,\n",
    "        cmap=\"gray\",\n",
    "        norm=simple_norm(img_data, \"linear\", max_percent=98),\n",
    "        origin='lower'\n",
    "    )\n",
    "\n",
    "    # *******  Input clusters *******\n",
    "    counter = 0\n",
    "    for i, (x, y) in enumerate(zip(x_AMAS, y_AMAS)):\n",
    "        # Check if source is within image bounds\n",
    "        if (0 <= x <= img_data.shape[1] and 0 <= y <= img_data.shape[0]):\n",
    "            ax.scatter(x, y,\n",
    "                    s=50,\n",
    "                    marker='s',\n",
    "                    facecolors='none',\n",
    "                    edgecolors='blue',\n",
    "                    linewidths=1.8,\n",
    "                    label=f\"Amas\" if counter == 0 else None)\n",
    "            counter += 1\n",
    "            \n",
    "            if show_ID_and_flux:    \n",
    "                # Format flux value\n",
    "                flux_str = \"{:.2e}\".format(clusters_myst['flux_ABS'][i]).replace('e-0', 'e-').replace('e+0', 'e+')\n",
    "                \n",
    "                # Add annotation\n",
    "                ax.annotate(\n",
    "                    f\"ID: {clusters_myst['ID'][i]}\\nFlux: {flux_str}\",\n",
    "                    xy=(x +  1.2, y),\n",
    "                    xytext=(5, 0),\n",
    "                    textcoords='offset points',\n",
    "                    color='red',\n",
    "                    fontsize=6,\n",
    "                    bbox=dict(facecolor='white', alpha=0.5, edgecolor='none'))\n",
    "\n",
    "    # ******* Input AGNs *******\n",
    "    counter = 0\n",
    "    for x, y in zip(x_AGN, y_AGN):\n",
    "        # Check if source is within image bounds\n",
    "        if (0 <= x <= img_data.shape[1] and 0 <= y <= img_data.shape[0]):\n",
    "            ax.scatter(x, y,\n",
    "                    s=50,\n",
    "                    marker='*',\n",
    "                    facecolors='none',\n",
    "                    edgecolors='red',\n",
    "                    linewidths=1.8,\n",
    "                    label=f\"AGN\" if counter == 0 else None)\n",
    "            counter += 1\n",
    "    \n",
    "    if(show_Xamin_sources): # Tracer les sources après Xamin (points verts)\n",
    "        coords_aft = SkyCoord(data_Xamin[\"PNT_RA\"], data_Xamin[\"PNT_DEC\"], frame='icrs', unit='deg')\n",
    "        #coords_aft = SkyCoord(Xamin_myst[\"PNT_RA\"], Xamin_myst[\"PNT_DEC\"], frame='icrs', unit='deg')\n",
    "        x_aft, y_aft = wcs.world_to_pixel(coords_aft)\n",
    "\n",
    "        counter = 0\n",
    "        for x, y in zip(x_aft, y_aft):\n",
    "            # Check if source is within image bounds\n",
    "            if (0 <= x <= img_data.shape[1] and 0 <= y <= img_data.shape[0]):\n",
    "                ax.scatter(x, y,\n",
    "                    s=50,\n",
    "                    marker='D',\n",
    "                    facecolors='none',\n",
    "                    edgecolors='limegreen',\n",
    "                    linewidths=0.9,\n",
    "                    label=f\"Xamin\"if counter == 0 else None)\n",
    "                counter += 1\n",
    "    \n",
    "    ax.set_xlim(0, img_data.shape[1])\n",
    "    ax.set_ylim(0, img_data.shape[0])\n",
    "    ax.set_xlabel('Right Ascension')\n",
    "    ax.set_ylabel('Declination')\n",
    "    ax.set_title(f\"Tile {ra}° {dec}° - Source Comparison\")\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plot_name = f\"Tile-{ra}-{dec}{'_mr' if mr else ''}_correlation_Rcluster{SEARCH_RADIUS_CLUSTER*3600:.2g}arcsec.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_name)\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Plot saved to: {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tile_centers = np.array([[146.75 + d_ra, 1.75 + d_dec] for d_ra in range(5) for d_dec in range(5)])\n",
    "\n",
    "def trouver_tuile(ra, dec):\n",
    "    \"\"\"\n",
    "    Trouve la tuile dont le centre est le plus proche des coordonnées données.\n",
    "    Paramètres: ra, dec : Coordonnées en degrés\n",
    "    Retourne: [ra_centre, dec_centre] : Coordonnées du centre de la tuile la plus proche\n",
    "    \"\"\"\n",
    "    coord = SkyCoord(ra, dec, unit='deg', frame='icrs')\n",
    "    tile_coords = SkyCoord(list_tile_centers[:,0], list_tile_centers[:,1], unit='deg', frame='icrs')\n",
    "    distances = coord.separation(tile_coords) # Calcul des distances en une seule opération vectorisée\n",
    "    i = np.argmin(distances)\n",
    "\n",
    "    return list_tile_centers[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "making_images = False\n",
    "if(making_images):\n",
    "    for d_ra in range(0,5):\n",
    "        for d_dec in range(0,5):\n",
    "            ra = 146.75 + d_ra\n",
    "            dec = 1.75 + d_dec\n",
    "            plot_tile_with_sources_after_correlation(ra = ra, \n",
    "                                                    dec = dec, \n",
    "                                                    mr = True,\n",
    "                                                    show_Xamin_sources = True,\n",
    "                                                    show_ID_and_flux = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tverif(id, mr,\n",
    "                show_Xamin_sources,\n",
    "                show_SExtractor=False,\n",
    "                NOMBRE_PHOTONS_MIN=40,\n",
    "                output_dir=\"~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Ambigous_images\",\n",
    "                imgs_dir=\"/local/home/sh275430/Documents/TransformerProject/data/catalogs/Data_10ks/imgs\",\n",
    "                catalog_path_SExtractor='~/Documents/TransformerProject/data/catalogs/Data_10ks/SEX'):\n",
    "    \"\"\"\n",
    "    Plot an image centered on a given source, with axes in arcminutes (ΔRA, ΔDec).\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Coordonnées de la source ---\n",
    "    ra_Xamin, dec_Xamin = data_Xamin[data_Xamin['ID_Xamin'] == id][['PNT_RA', 'PNT_DEC']][0]\n",
    "    ra_tile, dec_tile = trouver_tuile(ra_Xamin, dec_Xamin)\n",
    "\n",
    "    # --- Fichiers ---\n",
    "    imgs_dir = os.path.expanduser(imgs_dir)\n",
    "    output_dir = os.path.expanduser(output_dir + ('/Wavelets_images' if mr else '/Photons_images'))\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    img_file = f\"Tile-{ra_tile}-{dec_tile}_m12pn_b2_mosaic{'_mr' if mr else ''}.fits\"\n",
    "    img_path = os.path.join(imgs_dir, img_file)\n",
    "\n",
    "    # --- Lecture image FITS ---\n",
    "    with fits.open(img_path) as hdul:\n",
    "        img_data = hdul[0].data\n",
    "        header = hdul[0].header\n",
    "        wcs = WCS(header)\n",
    "\n",
    "    # --- Centre en pixels ---\n",
    "    center_pix = wcs.world_to_pixel(SkyCoord(ra_Xamin, dec_Xamin, unit='deg'))\n",
    "    x_center, y_center = center_pix\n",
    "\n",
    "    # --- Échelle en arcsec/pixel → arcmin ---\n",
    "    pix_scale = np.abs(wcs.proj_plane_pixel_scales()[0].to(u.arcsec).value)\n",
    "    pix_scale_arcmin = pix_scale / 60.0\n",
    "\n",
    "    # --- Rayon = 7 arcmin ---\n",
    "    radius_pix = int((4 * 60) / pix_scale)\n",
    "\n",
    "    # --- Définir les bords du crop ---\n",
    "    x_min = max(0, int(np.floor(x_center - radius_pix)))\n",
    "    x_max = min(img_data.shape[1], int(np.ceil(x_center + radius_pix)))\n",
    "    y_min = max(0, int(np.floor(y_center - radius_pix)))\n",
    "    y_max = min(img_data.shape[0], int(np.ceil(y_center + radius_pix)))\n",
    "\n",
    "    # --- Image crop ---\n",
    "    cropped_img = img_data[y_min:y_max, x_min:x_max]\n",
    "    ny, nx = cropped_img.shape\n",
    "\n",
    "    # Décalage en arcmin de chaque pixel par rapport au centre\n",
    "    x_extent = (np.array([0, nx]) - (x_center - x_min)) * pix_scale_arcmin\n",
    "    y_extent = (np.array([0, ny]) - (y_center - y_min)) * pix_scale_arcmin\n",
    "\n",
    "    # --- Axes arcmin centrés sur (0,0) ---\n",
    "    x_arcmin = (np.arange(nx) - (x_center - x_min)) * pix_scale_arcmin\n",
    "    y_arcmin = (np.arange(ny) - (y_center - y_min)) * pix_scale_arcmin\n",
    "\n",
    "    #print(f\"x_min={x_min}, x_max={x_max}, y_min={y_min}, y_max={y_max}\")\n",
    "    #print(f\"cropped_img.shape = {cropped_img.shape}\")\n",
    "    \n",
    "    # --- Figure ---\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # --- Affichage de l'image ---\n",
    "    vmin_fixed = 0.\n",
    "    vmax_fixed = 0.00004\n",
    "    ax.imshow(\n",
    "        cropped_img,\n",
    "        cmap=\"gray\",\n",
    "        vmin=vmin_fixed,\n",
    "        vmax=vmax_fixed,\n",
    "        origin='lower',\n",
    "        extent=[x_extent[0], x_extent[1], y_extent[0], y_extent[1]]\n",
    "    )\n",
    "\n",
    "    # --- Fonction pour filtrer et afficher les sources dans le champ ---\n",
    "    def plot_sources_arcmin(coords, marker, color, label, cross=False):\n",
    "        delta_ra = (coords.ra.deg - ra_Xamin) * 60 * np.cos(np.deg2rad(dec_Xamin))\n",
    "        delta_dec = (coords.dec.deg - dec_Xamin) * 60\n",
    "\n",
    "        mask = (\n",
    "            (delta_ra >= x_arcmin[0]) & (delta_ra <= x_arcmin[-1]) &\n",
    "            (delta_dec >= y_arcmin[0]) & (delta_dec <= y_arcmin[-1])\n",
    "        )\n",
    "\n",
    "        if cross:\n",
    "            ax.scatter(delta_ra[mask], delta_dec[mask],\n",
    "                       marker=marker, s=550, color=color, linewidths=2, label=label)\n",
    "        else:\n",
    "            ax.scatter(delta_ra[mask], delta_dec[mask],\n",
    "                       marker=marker, s=200, facecolors='none',\n",
    "                       edgecolors=color, linewidths=2, label=label)\n",
    "\n",
    "    # --- Affichage des sources ---\n",
    "    coords_clusters = SkyCoord(data_input_AMAS[\"R.A.\"], data_input_AMAS[\"Dec\"], unit='deg')\n",
    "    plot_sources_arcmin(coords_clusters, 's', 'blue', \"Clusters\")\n",
    "\n",
    "    coords_agn = SkyCoord(data_input_AGN[\"ra\"], data_input_AGN[\"dec\"], unit='deg')\n",
    "    plot_sources_arcmin(coords_agn, '*', 'blue', \"AGN\")\n",
    "\n",
    "    if show_Xamin_sources:\n",
    "        coords_xamin = SkyCoord(data_Xamin[\"PNT_RA\"], data_Xamin[\"PNT_DEC\"], unit='deg')\n",
    "        plot_sources_arcmin(coords_xamin, 's', 'limegreen', \"Xamin\")\n",
    "\n",
    "        data_Xamin['Ntot'] = 2 * data_Xamin['PNT_SCTS_MOS'] + data_Xamin['PNT_SCTS_PN']\n",
    "        sources_photons = data_Xamin[data_Xamin['Ntot'] > NOMBRE_PHOTONS_MIN]\n",
    "        coords_photons = SkyCoord(sources_photons[\"PNT_RA\"], sources_photons[\"PNT_DEC\"], unit='deg')\n",
    "        plot_sources_arcmin(coords_photons, '+', 'limegreen', f\"Xamin > {NOMBRE_PHOTONS_MIN}ph\", cross=True)\n",
    "\n",
    "    if show_SExtractor:\n",
    "        SEX_file = f\"Tile-{ra_tile}-{dec_tile}_m12pn_b2_SEXtra_cat.fits\"\n",
    "        SEX_path = os.path.join(os.path.expanduser(catalog_path_SExtractor), SEX_file)\n",
    "        data_SEX = Table.read(SEX_path)\n",
    "        coords_SEX = SkyCoord(data_SEX[\"xpeak_world\"], data_SEX[\"ypeak_world\"], unit='deg')\n",
    "        plot_sources_arcmin(coords_SEX, '^', '#E75480', \"SExtractor\")\n",
    "\n",
    "    # --- Mise en forme ---\n",
    "    ax.set_xlabel(\"ΔRA [arcmin]\", fontsize=22)\n",
    "    ax.set_ylabel(\"ΔDec [arcmin]\", fontsize=22)\n",
    "    ax.set_title(rf\"ID {id} - Flux amas > {LIM_FLUX_CLUSTER} $\\mathrm{{erg/cm^2/s}}$ - AGN > {LIM_FLUX_AGN} $\\mathrm{{erg/cm^2/s}}$\",\n",
    "                 pad=20, fontsize=18)\n",
    "    ax.legend(fontsize=15, facecolor='white')\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.set_ylim(-4, 4)\n",
    "    plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "    \n",
    "    # --- Sauvegarde ---\n",
    "    plot_name = f\"ID_{id}_7arcmin{'_mr' if mr else ''}.png\"\n",
    "    plot_path = os.path.join(output_dir, plot_name)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Plot saved to: {plot_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_48_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_49_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_50_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_52_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_53_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_54_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_55_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_56_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_57_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_58_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_59_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_60_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_61_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_63_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_65_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_66_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_67_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_72_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_76_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_80_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_81_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_82_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_83_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_84_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_86_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_88_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_89_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_90_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_93_7arcmin_mr.png\n",
      "Plot saved to: /local/home/sh275430/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious/Wavelets_images/ID_96_7arcmin_mr.png\n"
     ]
    }
   ],
   "source": [
    "List_id_of_spurious = data_NC['ID_Xamin']\n",
    "\n",
    "if(True):\n",
    "    for id in List_id_of_spurious[25:55]:\n",
    "        plot_tverif(id=id , mr = True, show_Xamin_sources = True, show_SExtractor = True, NOMBRE_PHOTONS_MIN = 40,\n",
    "                    output_dir=\"~/Documents/TransformerProject/results/Correl_clusters_agn_10ks/Spurious\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "making_images = False\n",
    "if(making_images):\n",
    "    for id in common_ids[:2]:\n",
    "        plot_tverif(id=id , mr = True, show_Xamin_sources = True)\n",
    "\n",
    "        cluster_info = clusters_myst[clusters_myst['ID_Xamin'] == id]\n",
    "        \n",
    "        if len(cluster_info) > 0:  # Check if any matches were found\n",
    "            print(f\"Identifiant de l'amas central : {cluster_info['ID'][0]}\")\n",
    "            print(f\"Flux de l'amas central : {cluster_info['flux_ABS'][0]}\")\n",
    "        else:\n",
    "            print(f\"Aucun amas trouvé avec ID_Xamin = {id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
